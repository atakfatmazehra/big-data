{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "veri_on_isleme.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNen9oGWtlkPfOoirE12JXg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atakfatmazehra/big-data/blob/master/veri_on_isleme.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x_ZYoUAg1Nh",
        "outputId": "e4806c27-a36e-4efe-f035-d37410d2c8de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     FR   TR   US  boy  kilo  yas cinsiyet\n",
            "0   0.0  1.0  0.0  130    30   10        e\n",
            "1   0.0  1.0  0.0  125    36   11        e\n",
            "2   0.0  1.0  0.0  135    34   10        k\n",
            "3   0.0  1.0  0.0  133    30    9        k\n",
            "4   0.0  1.0  0.0  129    38   12        e\n",
            "5   0.0  1.0  0.0  180    90   30        e\n",
            "6   0.0  1.0  0.0  190    80   25        e\n",
            "7   0.0  1.0  0.0  175    90   35        e\n",
            "8   0.0  1.0  0.0  177    60   22        k\n",
            "9   0.0  0.0  1.0  185   105   33        e\n",
            "10  0.0  0.0  1.0  165    55   27        k\n",
            "11  0.0  0.0  1.0  155    50   44        k\n",
            "12  0.0  0.0  1.0  160    58   39        k\n",
            "13  0.0  0.0  1.0  162    59   41        k\n",
            "14  0.0  0.0  1.0  167    62   55        k\n",
            "15  1.0  0.0  0.0  174    70   47        e\n",
            "16  1.0  0.0  0.0  193    90   23        e\n",
            "17  1.0  0.0  0.0  187    80   27        e\n",
            "18  1.0  0.0  0.0  183    88   28        e\n",
            "19  1.0  0.0  0.0  159    40   29        k\n",
            "20  1.0  0.0  0.0  164    66   32        k\n",
            "21  1.0  0.0  0.0  166    56   42        k\n",
            "[[-0.63245553  0.8660254  -0.40824829  0.45049444 -0.29657884 -0.26680787]\n",
            " [-0.63245553  0.8660254  -0.40824829  1.00824945  0.5096549   0.        ]\n",
            " [ 1.58113883 -1.15470054 -0.40824829  1.13696215  0.91277178 -0.17787191]\n",
            " [-0.63245553  0.8660254  -0.40824829 -1.6089087  -1.18343596 -1.15616745]\n",
            " [-0.63245553  0.8660254  -0.40824829 -1.35148331 -1.34468271 -1.33403936]\n",
            " [-0.63245553  0.8660254  -0.40824829  0.57920713  0.91277178  0.44467979]\n",
            " [ 1.58113883 -1.15470054 -0.40824829  0.87953676  0.5096549   0.17787191]\n",
            " [-0.63245553 -1.15470054  2.44948974  0.79372829  1.51744708  0.71148766]\n",
            " [-0.63245553  0.8660254  -0.40824829  0.36468597  0.91277178  0.88935957]\n",
            " [ 1.58113883 -1.15470054 -0.40824829  0.70791983  0.8321484   0.26680787]\n",
            " [-0.63245553  0.8660254  -0.40824829 -1.43729177 -1.50592946 -1.42297532]\n",
            " [-0.63245553  0.8660254  -0.40824829 -1.56600447 -1.50592946 -1.33403936]\n",
            " [ 1.58113883 -1.15470054 -0.40824829  0.32178174  0.10653803  1.95659106]\n",
            " [-0.63245553 -1.15470054  2.44948974 -0.27887751 -0.37720222  1.2451034 ]]\n",
            "[[ 1.29099445 -0.37796447 -1.          0.47240026  1.32853794 -0.24991255]\n",
            " [-0.77459667 -0.37796447  1.          0.54952683  0.20439045 -0.64977262]\n",
            " [-0.77459667 -0.37796447  1.          0.70377998  0.91975703  1.58944379]\n",
            " [-0.77459667 -0.37796447  1.          0.31814711  0.61317136  0.46983559]\n",
            " [-0.77459667  2.64575131 -1.         -2.53553608 -1.73731884 -1.92932485]\n",
            " [ 1.29099445 -0.37796447 -1.          0.6266534   0.30658568  0.5498076 ]\n",
            " [-0.77459667 -0.37796447  1.         -0.2217389  -0.30658568  0.70975163]\n",
            " [ 1.29099445 -0.37796447 -1.          0.08676739 -1.32853794 -0.48982859]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "#DOSYAYI OKUMA\n",
        "veriler = pd.read_csv(\"veriler.csv\")\n",
        "#print(veriler)\n",
        "\n",
        "#VERİ ÖN İŞLEME\n",
        "boy=veriler[[\"boy\"]]\n",
        "#print(boy)\n",
        "\n",
        "boykilo=veriler[[\"boy\",\"kilo\"]]\n",
        "#print(boykilo)\n",
        "\n",
        "#EKSİK VERİLERİ TAMAMLAMA İŞLEMİ\n",
        "\n",
        "#SCİ-KİT LEARN\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer= SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "\n",
        "Yas= veriler.iloc[:,1:4].values\n",
        "#print(Yas)\n",
        "imputer=imputer.fit(Yas[:,1:4]) #fit=öğrenme metodudur\n",
        "#sayısal verileri öğren\n",
        "Yas[:,1:4]=imputer.transform(Yas[:,1:4])#transform ile değiştir, öğrendikleriyle\n",
        "#print(Yas)\n",
        "\n",
        "#VERİLERİ KATEGORİLEŞTİRME\n",
        "ulke = veriler.iloc[:,0:1].values #birinci kolondakileri aldık\n",
        "#1.kolonda ülke adları var. her ülkeyi ayrı kolan olarak tanımlıcaz\n",
        "#print(ulke)\n",
        "\n",
        "from sklearn import preprocessing\n",
        "le= preprocessing.LabelEncoder()\n",
        "\n",
        "ulke[:,0]= le.fit_transform(veriler.iloc[:,0])\n",
        "#fit=öğrenme transform=uygulama\n",
        "#:,0 ilk sutün demek\n",
        "#print(\"TR== 1  /  US==2 / FR==0\")\n",
        "#print(ulke)\n",
        "\n",
        "ohe = preprocessing.OneHotEncoder() #ohe= 2li cevirir 0/1 yani\n",
        "ulke = ohe.fit_transform(ulke).toarray() \n",
        "#print(\"1.sutün=FR / 2.sutün=TR / 3.sutün=US\")\n",
        "#print(ulke)\n",
        "\n",
        "#VERİLERİN BİRLEŞTİRİLMESİ\n",
        "sonuc = pd.DataFrame(data=ulke, index = range(22), columns=[\"FR\",\"TR\",\"US\"]) #22satırımız oldugu için\n",
        "#print(sonuc)\n",
        "\n",
        "sonuc2= pd.DataFrame(data=Yas, index=range(22), columns=[\"boy\",\"kilo\",\"yas\"])\n",
        "#print(sonuc2)\n",
        "\n",
        "cinsiyet= veriler.iloc[:,-1].values\n",
        "#print(cinsiyet)\n",
        "\n",
        "sonuc3= pd.DataFrame(data=cinsiyet, index=range(22), columns=[\"cinsiyet\"])\n",
        "#print(sonuc3)\n",
        "\n",
        "tam_sonuc= pd.concat([sonuc,sonuc2], axis=1)\n",
        "#axis=1 1.colonlar arasında eşleşme yapar\n",
        "#concat=iki dataframe arasında işlem yapar, birleştirir\n",
        "\n",
        "tam_sonuc2= pd.concat([tam_sonuc,sonuc3], axis=1)\n",
        "print(tam_sonuc2)\n",
        "\n",
        "#VERİ KÜMESİNİN EĞİTİLMESİ\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "#verileri böleceğiz\n",
        "#bağımsız(ülke, yas) ve bağımlı(hedef=cinsiyet) değişken\n",
        "#yüzde33=test  yüzde67=train yani model eğitim için\n",
        "x_train, x_test, y_train, y_test = train_test_split(tam_sonuc,sonuc3, test_size=0.33, random_state=0)\n",
        "#x=test y=train\n",
        "# yatayda 2  dikeyde 2 toplam 4 veri seti çıkar\n",
        "\n",
        "#ÖZNİTELİK ÖLÇEKLENDİRME\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc= StandardScaler()#farklı dünyalardaki verileri aynı dünyaya çektik\n",
        "#yani biri 100ler biri 10lar ama bunu standardscaler ile aynı boyuta indirgedik\n",
        "X_train = sc.fit_transform(x_train)\n",
        "X_test= sc.fit_transform(x_test)\n",
        "print(X_train)\n",
        "print(X_test)\n",
        "\n",
        "\n"
      ]
    }
  ]
}